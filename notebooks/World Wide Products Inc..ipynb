{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Wide Products Inc.\n",
    "\n",
    "#### Introduction\n",
    "Many products are sold; however, depending on the season, some products are in more demand than others. Given a data set with order dates and demand quanitity, can the future demand be forecasted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR #GBM algorithm\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#Import dataset\n",
    "products=pd.read_csv('../data/external/Historical Product Demand.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n",
    "\n",
    "The current dataset contains five attributes: product code, warehouse, product category, date needed and order quanitity. Using Google Facets, no data is missing; however, a few dates are labeled as NA. Due to this, these are dropped.\n",
    "\n",
    "Furthermore, the order demand needs normalization due to the massive range and majority of orders under 400 versus 4 million. A few of these entries contain values other than only digits. This is fixed.\n",
    "\n",
    "For machine learning, it's better to input numerical data. For product category, the \"category_\" string is dropped. This is similar with product code \"Product_\". These numbers need to be readjusted so it does not affect scaling. Lastly, the warehouse is hashed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NA dates\n",
    "products=products[products['Date'] != 'NA']\n",
    "products=products.dropna(subset=['Date'])\n",
    "\n",
    "#Normalize order demand\n",
    "products['Order_Demand']=products['Order_Demand'].str.replace('[^0-9]', '', regex=True)\n",
    "products['Order_Demand']=products['Order_Demand'].astype(\"int\")\n",
    "products['Order_Demand']=(products['Order_Demand']-products['Order_Demand'].min())/(products['Order_Demand'].max()-products['Order_Demand'].min())\n",
    "\n",
    "products['Product_Category']=products['Product_Category'].str.replace('[^0-9]','',regex=True)\n",
    "products['Product_Code']=products['Product_Code'].str.replace('[^0-9]','',regex=True)\n",
    "\n",
    "products['Warehouse']=products['Warehouse'].apply(hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Since date contains a day, month and year, this is extracted into separate columns. Furthermore, seasons can be extracted; however, the assumption is the products are demanded by USA.\n",
    "\n",
    "These seasons are defined as followed:\n",
    "\n",
    "* Spring(1): Mar(3) 20 - Jun(6) 20\n",
    "\n",
    "* Summer(2): Jun(6) 21 - Sept(9) 21\n",
    "\n",
    "* Fall(3): Sept(9) 22 - Dec(12) 20\n",
    "\n",
    "* Winter(4): Dec(12) 21 - Mar(3) 19\n",
    "\n",
    "However this is difficult to program as days in the month reset after each month. By labeling the day in the year, a numerical range exists. This is as below:\n",
    "\n",
    "* Spring(1): [80-172)\n",
    "\n",
    "* Summer(2): [172-264)\n",
    "\n",
    "* Fall(3): [264-355)\n",
    "\n",
    "* Winter(4): All else\n",
    "\n",
    "Aside from season, day of the week, week and weekday is extracted from the date.\n",
    "\n",
    "Lastly, all data needs to be numerical. The date is output into YearMonthDay format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['Date']=pd.to_datetime(products['Date'])\n",
    "\n",
    "products['DayofWeek']=products.Date.apply(lambda x: pd.Timestamp.isoweekday(x))\n",
    "products['DayofYear']=products.Date.dt.dayofyear\n",
    "products['Week']=products.Date.dt.week\n",
    "products['Isweekday']=products.Date.dt.weekday\n",
    "products['Isweekday']=np.where(products['Isweekday'] >0,1,0)\n",
    "\n",
    "products['Season']=np.where((products.DayofYear>79)&(products.DayofYear<172), 1, 4)\n",
    "products['Season']=np.where((products.DayofYear>171)&(products.DayofYear<265), 2, products['Season'])\n",
    "products['Season']=np.where((products.DayofYear>264)&(products.DayofYear<356), 3, products['Season'])\n",
    "\n",
    "\n",
    "products['Date'] = products.Date.dt.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Data\n",
    "Before applying the model, the data requires subsetting into training, test and validation. This is parsed based on dates such that 10% of the closest dates are validation, the next 10% of dates is testing and the rest of the dates are training. \n",
    "\n",
    "The total amount of data is 1,037,336 thus 10 percent is 103,733 such that testing and validation are a total of 207,467. Since the dataset is already sorted based on date, this can be parsed by location.\n",
    "\n",
    "With a bit of curiosity, the data is also randomly sampled into these three categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "training=products.iloc[0:829870,:]\n",
    "testing=products.iloc[829870:933603,:]\n",
    "validation=products.iloc[933603:1037336,:]\n",
    "\n",
    "train_y=training['Order_Demand']\n",
    "train_x=training.drop(columns=['Order_Demand'])\n",
    "\n",
    "test_y=testing['Order_Demand']\n",
    "test_x=testing.drop(columns=['Order_Demand'])\n",
    "\n",
    "val_y=validation['Order_Demand']\n",
    "val_x=validation.drop(columns=['Order_Demand'])\n",
    "\n",
    "featu=products.drop(columns=['Order_Demand'])\n",
    "\n",
    "#Convert to numpy array\n",
    "features=np.array(featu)\n",
    "label=products['Order_Demand']\n",
    "\n",
    "#---------Training/Testing/Validation as previously done in homeworks--------\n",
    "x, x_test, y, y_test = train_test_split(features,label,test_size=0.1,train_size=0.9)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size = 0.15,train_size =0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling\n",
    "\n",
    "For each product, determining the demand requires forecasting. With multiple products to forecast, a two models are implemented: Gradient Boosting and Random Forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "algorithm=GBR()\n",
    "algorithm.fit(train_x,train_y)\n",
    "\n",
    "predictions=algorithm.predict(test_x)\n",
    "print('Parsed on date relevance:')\n",
    "print ('R-squared Test: ', algorithm.score(test_x,test_y))\n",
    "predVal=algorithm.predict(val_x)\n",
    "print('R-squared Test: ', algorithm.score(val_x,val_y))\n",
    "\n",
    "\n",
    "predictions=algorithm.predict(x_test)\n",
    "print('Parsed randomly:')\n",
    "print ('R-squared Test: ', algorithm.score(x_test,y_test))\n",
    "predVal=algorithm.predict(x_val)\n",
    "print('R-squared Test: ', algorithm.score(x_val,y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forests\n",
    "rf=RFR()\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "predictions=rf.predict(test_x)\n",
    "print('Parsed on date relevance:')\n",
    "print ('R-squared Test: ', rf.score(test_x,test_y))\n",
    "predVal=rf.predict(val_x)\n",
    "print('R-squared Test: ', rf.score(val_x,val_y))\n",
    "\n",
    "\n",
    "predictions=rf.predict(x_test)\n",
    "print('Parsed randomly:')\n",
    "print('R-squared Test: ', rf.score(x_test,y_test))\n",
    "predictions=rf.predict(x_val)\n",
    "print('R-squared Test: ', rf.score(x_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Comparing and contrasting gradient boosting with random forests, random forests performed the best with test data based on recent dates. Unfortunately, it did not perform well with the validation set which contained the most recent date orders. The success is measured based on the R squared technique. A value closer to 1 indicates a better graph of data variance. Random forests ranged between 0.110 and 0.556. Gradient boosting ranged between 0.074 and 0.204. \n",
    "\n",
    "The lack of determined variance fit could be due to the lack of features. Certain weather conditions can also affect orders as well as warehouse reputations. By only using date information and order information as well as source, these two models do not forecast as well.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "As stated before, many orders are placed based on supply and demand. By using gradient boosting and random forests, one can forecast the demand. However, with a R squared score under 0.56 for both models, this does not prove highly efficient. \n",
    "\n",
    "\n",
    "## References\n",
    "#### How to determine seasons\n",
    "https://www.almanac.com/content/first-day-seasons \n",
    "https://stackoverflow.com/questions/16139306/determine-season-given-timestamp-in-python-using-datetime?rq=1 \n",
    "\n",
    "#### To understand how all products can be used for forecasting and what works the best for this dataset\n",
    "https://datascience.stackexchange.com/questions/31267/demand-forecasting-for-multiple-products-across-thousands-of-stores\n",
    "\n",
    "#### How to use gradient boosting\n",
    "https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/ \n",
    "\n",
    "https://shankarmsy.github.io/stories/gbrt-sklearn.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
